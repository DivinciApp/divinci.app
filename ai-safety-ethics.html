<!doctype html>
<html lang="en">
    <head>
        <meta charset="UTF-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <link
            rel="apple-touch-icon"
            sizes="180x180"
            href="/apple-touch-icon.png"
        />
        <link
            rel="icon"
            type="image/png"
            sizes="32x32"
            href="images/favicon-32x32.png"
        />
        <link
            rel="icon"
            type="image/png"
            sizes="16x16"
            href="images/favicon-16x16.png"
        />
        <title>Divinci AI Safety, Trust & Ethics Statement</title>
        <link
            rel="stylesheet"
            href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css"
        />
        <link rel="stylesheet" href="styles.css" />
    </head>
    <body>
        <!-- Navbar and hero section here if needed -->
        <nav class="navbar">
            <a href="index.html">
                <img
                    class="nav-logo"
                    src="images/divinci_logo.png"
                    alt="Divinci Heart Robot logo black and white"
                />
            </a>
            <div class="nav-title">Divinci AI - Safety, Trust and Ethics</div>
            <div class="nav-menu">
                <a href="#features">Features</a>
                <a href="#team">Team</a>
                <a href="#signup">Sign Up</a>
            </div>
        </nav>

        <!-- AI Trust & Ethics Statement Section -->
        <section class="section" id="ai-trust-ethics">
            <div class="container">
                <h1 class="title">AI Safety, Trust and Ethics Statement</h1>
                <p class="subtitle">
                    Divinci AI’s Commitment to Responsible and Trustworthy AI
                </p>

                <div class="content">
                    <p>
                        At Divinci AI, we prioritize safe, ethical, and
                        transparent AI solutions. Our products, including web
                        and mobile applications, serve diverse use cases in
                        healthcare and other sensitive fields. This document
                        details our commitment to using only licensed data,
                        ensuring rigorous safety measures, and implementing
                        robust human interfaces in our Retrieval-Augmented
                        Generation (RAG) and Fine-Tuned language models.
                    </p>

                    <!-- Licensed Data and Responsible AI Development -->
                    <h2>1. Licensed Data and Responsible AI Development</h2>
                    <p>
                        We are committed to using only licensed and ethically
                        sourced data in training our AI models. Our data
                        governance practices ensure that every dataset is
                        verified for legitimacy, licensing compliance, and
                        relevance. This approach aligns with guidelines like
                        those set by ANSI for trustworthy AI, emphasizing
                        transparency and ethical sourcing
                        <a href="#"
                            >(Guidelines for Developing Trustworthy AI)</a
                        >
                        <a href="#">(Recommended Practice for AI Governance)</a
                        >.
                    </p>

                    <!-- Human-Centered Safety and Moderation -->
                    <h2>2. Human-Centered Safety and Moderation</h2>
                    <p>
                        Divinci AI integrates human moderation interfaces across
                        all custom AI solutions to foster responsible use and
                        prevent misuse. These interfaces support:
                    </p>
                    <ul>
                        <li>
                            <strong>Content Management:</strong> We provide
                            tools for reviewing, editing, and controlling the
                            information our AI models generate, helping to align
                            responses with ethical standards.
                        </li>
                        <li>
                            <strong>Testing and Validation:</strong> Every model
                            goes through rigorous testing to minimize bias,
                            confabulation, and misinformation
                            <a href="#"
                                >(Emotion enabled multimodal user interface)</a
                            >
                            <a href="#">(AI Risk Management Framework)</a>.
                        </li>
                        <li>
                            <strong>Release Management:</strong> Our models
                            undergo controlled release processes to ensure they
                            are only deployed once they meet our high safety and
                            reliability standards.
                        </li>
                    </ul>

                    <!-- Safety Features in Consumer and Patient-Facing Models -->
                    <h2>
                        3. Safety Features in Consumer and Patient-Facing Models
                    </h2>
                    <p>
                        For applications involving consumers or patients,
                        Divinci AI incorporates robust safety features such as:
                    </p>
                    <ul>
                        <li>
                            <strong>Transparency and Explainability:</strong> We
                            strive for clarity in AI responses, helping users
                            understand how decisions are made and why specific
                            recommendations appear. This commitment reduces
                            over-reliance and ensures user trust
                            <a href="#"
                                >(Guidelines for Developing Trustworthy AI)</a
                            >
                            <a href="#">(The Use of AI in Health Care)</a>.
                        </li>
                        <li>
                            <strong>Moderation for Harmful Content:</strong> We
                            actively moderate against harmful outputs, including
                            any content that may be biased, inappropriate, or
                            potentially misleading. Our systems implement
                            safeguards to monitor and restrict outputs that
                            could negatively impact users
                            <a href="#">(AI Risk Management Framework)</a>.
                        </li>
                    </ul>

                    <!-- Trust, Transparency, and User Accountability -->
                    <h2>4. Trust, Transparency, and User Accountability</h2>
                    <p>
                        Divinci AI fosters trust by creating transparent AI
                        solutions. We provide clear user guidelines, outlining
                        system capabilities, limitations, and ethical
                        constraints. For healthcare applications, we follow
                        ANSI’s standards to align our systems with trusted
                        guidelines on data privacy, bias mitigation, and
                        compliance with relevant regulatory standards
                        <a href="#">(The Use of AI in Health Care)</a>.
                    </p>

                    <!-- AI Governance and Compliance -->
                    <h2>5. AI Governance and Compliance</h2>
                    <p>
                        Our adherence to the AI governance framework aligns with
                        standards like those from NIST and IEEE, focusing on
                        accountability, transparency, and robust performance
                        metrics. Regular audits of our systems ensure that our
                        AI models remain aligned with Divinci AI’s ethical
                        standards throughout their lifecycle
                        <a href="#">(Recommended Practice for AI Governance)</a
                        >.
                    </p>

                    <!-- Acknowledgment to AI Standards Hub -->
                    <h2>Acknowledgment</h2>
                    <p>
                        We’d like to thank
                        <a href="https://aistandardshub.org/" target="_blank"
                            >The Alan Turing Institute’s AI Standards Hub</a
                        >
                        for providing invaluable AI standards resources that
                        have inspired and informed Divinci AI’s AI Safety and
                        Ethics policies.
                    </p>
                </div>
            </div>
        </section>

        <!-- Footer section -->
        <footer class="site-footer">
            <div class="container">
                <p>&copy; 2024 Divinci AI Inc. All rights reserved.</p>
                <p>
                    <a href="ai-safety-ethics.html">AI Safety & Ethics</a> |
                    <a href="terms-of-service.html">Terms of Service</a>
                </p>
            </div>
        </footer>
    </body>
</html>
